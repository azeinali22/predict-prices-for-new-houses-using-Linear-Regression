# -*- coding: utf-8 -*-
"""LR-Zeinali_Dehaghani.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MIVhwRvMaetfLgrEPTMcqT9QGN2B_dx0
"""

from google.colab import drive
drive.mount('/content/drive')

# Required Libraries:
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Load the dataset:
df = pd.read_csv("/content/drive/MyDrive/COMP-5011-Assignment1-LinearRegression/Housing.csv")

# Extract features that should be Consider according to Assignment Tasks:
required_features = ["area", "bedrooms", "hotwaterheating", "airconditioning", "bathrooms","price"]
df = df[required_features]
df.head(4)

# Size of Data set
df.shape

# Summarize the structure of loaded dataset
df.info()

# quantitative summary of the numerical columns in dataset
df.describe()

#Check for missing values
print("Missing values in each column:", df.isnull().sum())

# Convert categorical features (hotwaterheating and airconditioning) to binary. (0= No, 1= Yes)
df["hotwaterheating"] = [0 if i=="no" else 1 for i in df["hotwaterheating"]]
df["airconditioning"] = [0 if i=="no" else 1 for i in df["airconditioning"]]
df.head()

# Select features to scale (excluding the target variable 'price')
features_to_scale = df[['area', 'bedrooms', 'hotwaterheating', 'airconditioning', 'bathrooms']]

# Fit and transform the selected features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features_to_scale)

# Convert scaled features back to a DataFrame and Add the target variable back (price) to the scaled DataFrame
scaled_df = pd.DataFrame(scaled_features, columns=['area', 'bedrooms', 'hotwaterheating', 'airconditioning', 'bathrooms'])
scaled_df['price'] = df['price'].values

scaled_df.head()

# Extract features and the target variable
features = scaled_df.drop('price', axis=1)
target = scaled_df['price']

# Loop through each feature and create a scatter plot
for feature in features.columns:
    plt.figure(figsize=(8, 5))
    sns.scatterplot(x=features[feature], y=target)
    plt.title(f'Relationship between {feature} and Price')
    plt.xlabel(feature)
    plt.ylabel('Price ($)')
    plt.grid(True)
    plt.show()


# Compute the correlation matrix
correlation_matrix = scaled_df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, linewidths=0.5)
plt.title('Correlation Matrix Heatmap')
plt.show()

X = scaled_df.drop('price', axis=1)  # Features (independent variables)
y = scaled_df['price']               # Target variable (dependent variable (price))

# Split the data into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

#Shapes of the Train and Test datasets
print(f'Train set size: {X_train.shape}')
print(f'Test set size: {X_test.shape}')

X_b_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]  # Add intercept
X_b_test = np.c_[np.ones((X_test.shape[0], 1)), X_test]    # Add intercept for test set

#Calculate parameters using Normal Equation
theta_best = np.linalg.inv(X_b_train.T.dot(X_b_train)).dot(X_b_train.T).dot(y_train)

#Extract intercept (b) and slopes (m)
b = theta_best[0]  # Intercept
m = theta_best[1:]  # Slopes for each feature

#Function to predict values
def predict(X, b, m):
    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add intercept
    return X_b.dot(np.r_[b, m])  # Concatenate b with m for predictions

#Make predictions on the test dataset
predictions = predict(X_test, b, m)

#Showing predicted value (price), Actual value (price) and difference of them
for i in range(len(predictions)):
    print(f"Predicted Price: {int(predictions[i])}    |   Actual Price: {y_test.values[i]}    |    difference:{int(predictions[i])-y_test.values[i]}")

# Evaluate the model using MSE, MAE, and R² Score
mse = mean_squared_error(y_test, predictions)
mae = mean_absolute_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

# Print the evaluation metrics
print("MSE:", mse.__round__(2))
print("MAE:", mae.__round__(2))
print("R² Score:", r2.__round__(2))

#Compare the predicted values with actual values using a scatter plot (predicted vs.actual)

plt.figure(figsize=(10, 6))
plt.scatter(y_test, predictions, color='blue', alpha=0.6)  # Actual vs Predicted
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)  # Diagonal line
plt.title('Actual Prices vs Predicted Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.grid(True)
plt.xlim([0, max(y_test.max(), predictions.max())])  # Set x and y limits
plt.ylim([0, max(y_test.max(), predictions.max())])
plt.gca().set_aspect('equal', adjustable='box')  # Equal aspect ratio
plt.show()